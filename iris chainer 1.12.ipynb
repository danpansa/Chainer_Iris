{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import training, datasets\n",
    "from chainer.training import extensions\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = iris.target\n",
    "Y = Y.flatten().astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train ,test= datasets.split_dataset_random(chainer.datasets.TupleDataset(X,Y),100)\n",
    "train_iter = chainer.iterators.SerialIterator(train, 10)\n",
    "test_iter = chainer.iterators.SerialIterator(test, 1,repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IrisModel(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(IrisModel,self).__init__(\n",
    "                l1 = L.Linear(4,100),\n",
    "                l2 = L.Linear(100,100),\n",
    "                l3 = L.Linear(100,3))\n",
    "\n",
    "    def __call__(self,x):    \n",
    "         h = F.relu(self.l1(x))\n",
    "         h = F.relu(self.l2(h))\n",
    "         return self.l3(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = L.Classifier(IrisModel())\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=-1)\n",
    "trainer = training.Trainer(updater, (30, 'epoch'), out=\"result\")\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=-1))\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.PrintReport( ['epoch', 'main/loss', 'validation/main/loss', 'main/accuracy', 'validation/main/accuracy']))\n",
    "# trainer.extend(extensions.ProgressBar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[Jepoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy\n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J1           1.23951     1.03659               0.42           0.56                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J2           0.746208    0.694044              0.74           0.78                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J3           0.555498    0.61899               0.77           0.56                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J4           0.448438    0.501323              0.85           0.8                       \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J5           0.384808    0.43386               0.85           0.88                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J6           0.343886    0.397124              0.9            0.88                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J7           0.311689    0.357416              0.92           0.9                       \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J8           0.283019    0.319386              0.96           0.9                       \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J9           0.257954    0.290414              0.97           0.94                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J10          0.23681     0.268185              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J11          0.217634    0.245335              0.96           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J12          0.201869    0.226008              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J13          0.188083    0.209219              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J14          0.176332    0.194392              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J15          0.166238    0.180978              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J16          0.157597    0.169269              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J17          0.150323    0.15905               0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J18          0.144024    0.150328              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J19          0.138576    0.142811              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J20          0.133919    0.136215              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J21          0.129842    0.130394              0.97           0.96                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J22          0.126315    0.125188              0.97           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J23          0.123218    0.120566              0.96           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J24          0.120436    0.116444              0.96           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J25          0.117928    0.112616              0.96           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J26          0.115631    0.109026              0.96           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J27          0.11361     0.105685              0.96           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J28          0.111719    0.102632              0.96           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J29          0.11012     0.0997764             0.96           0.98                      \n",
      "\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J\u001b[J30          0.108482    0.0973794             0.96           0.98                      \n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76944584,  0.18974303,  0.03136431,  0.00944675]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(np.array([test[0][0]])).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(np.array([test[0][0]])).data.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25907731,  0.11319122,  0.6277315 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predictor(np.array([[1,  1,  1,  1  ]]).astype(np.float32))\n",
    "F.softmax(y).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(y).data.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25907731,  0.11319122,  0.6277315 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model.predictor(np.array([[1,  1,  1,  1  ]]).astype(np.float32))).data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
